{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUZZY LANGUAGE\n",
    "\n",
    "This project aimed at creating firsthand intuitions while dealing with fuzzy lanague at work place. \n",
    "Fuzzy language is vague language that is commonly practiced in workplace. Hence, data practitioners need to be able to make it precise. When dealing with a vague request, it is important to ask yourself following questions:\n",
    "- What is the reason behind the request?\n",
    "- What is the right question to ask?\n",
    "\n",
    "\n",
    "The artificial environment was set up in a large retail company and you acted as a data analyst in online department. You were currently working on customer segmentation (Customer segmentation is the partitioning of customers into groups using criteria like age bracket, gender, geographic location, buying tendencies and so many more). The goal of your task was to determine which segments would increase sales the most and target them with ads in social media. One day, your manager passed by your desk on his way to a meeting and quickly asked you to figure out who \"your best customers\" were. You were too focused on your previous tasks and because the manager was in a hurry, you simply said \"Yes\" and forgot about it for some time. When you finally got back to the request given by the manager, you realized that your manager gave quite a vague request, not knowing depending on which criteria to determine the best customers. \n",
    "\n",
    "Now moving back to 2 questions mentioned above, you need to clarify with your manager what he really wanted with the best customers. You then ran to the manager and asked him what his end goal of this request was. He said he was in a rush and forgot to mention! (*This unfortunately happens quite a lot* :) )He then told you that the department had like $100 left in marketing budget and it would not roll over to next year. So that the money could be used to try and convert some physical store customers to online store by sending these customers coupons for online usage, but he stated clearly not to steal any customers from physical store. He also mentioned that the task had to be done by ... today! Since it was a rush, the manager reached out to other department and got data from them and sent it to you by email. So now you got the data to complete the request. \n",
    "\n",
    "The data can be found with [here](https://www.kaggle.com/regivm/retailtransactiondata). The dataset has 3 columns:\n",
    "- customer_id: Customer identification number\n",
    "- trans_date: Transaction date\n",
    "- tran_amount: Transaction amount\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>tran_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5896</td>\n",
       "      <td>FM4039</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99551</td>\n",
       "      <td>FM1275</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42873</td>\n",
       "      <td>FM4064</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77207</td>\n",
       "      <td>FM5991</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119035</td>\n",
       "      <td>FM7291</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22062</td>\n",
       "      <td>FM4608</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7897</td>\n",
       "      <td>FM6090</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4343</td>\n",
       "      <td>FM4657</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85200</td>\n",
       "      <td>FM4477</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>FM2177</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id trans_date  tran_amount\n",
       "5896        FM4039 2019-12-16          102\n",
       "99551       FM1275 2019-12-16           74\n",
       "42873       FM4064 2019-12-16           42\n",
       "77207       FM5991 2019-12-16           42\n",
       "119035      FM7291 2019-12-16           65\n",
       "22062       FM4608 2019-12-16           47\n",
       "7897        FM6090 2019-12-16           74\n",
       "4343        FM4657 2019-12-16          100\n",
       "85200       FM4477 2019-12-16           44\n",
       "3150        FM2177 2019-12-16           80"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "data = pd.read_csv(\"rfm_xmas19.txt\", parse_dates=[\"trans_date\"]) # read in file\n",
    "data.sort_values(\"trans_date\", inplace= True, ascending= False) # sort trans_date column\n",
    "data.head(10) #print first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the table above that the latest transaction is 16.12.2019.\n",
    "\n",
    "After thinking for a while, the concept of \"your customers\" can be ambiguous as it could refer to company's customers or just online customers. For clarification, it actually refers to customers of company that have never purchased online. So here is the best reply that you should deliver to your manager (all in one):\n",
    "- What you want from me is the list of best physical store customers (name, mail address) that have never purchased online to send coupons to.\n",
    "- Use my best judgements to figure out the value of coupons should be and how many coupons to give out.\n",
    "- I should figure out what criteria to assess the best customers. \n",
    "- Make sure not stealing any of customers from physical stores.\n",
    "- Then I propose to send coupons to best churned customers in the last 3 months (could be 4 months, just for testing). \n",
    "\n",
    "## Modify original dataset into dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_customer = data.groupby(\"customer_id\") # group all transactions by customers\n",
    "last_trans = group_by_customer[\"trans_date\"].max() # take only the lastest transactions since 1 customer can have many transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lastest transaction is 16.12.2019, 3 months before, which is the cutoff day is 16.09.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_day = dt.datetime(2019, 9, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_churn = pd.DataFrame(last_trans) # have data with last transaction as a dataframe\n",
    "\n",
    "# add a column named \"churned\" to the dataframe that should have value of 1 if the customer has churned or 0 if not\n",
    "\n",
    "best_churn[\"churned\"] = best_churn[\"trans_date\"].apply(lambda date: 1 if date < cutoff_day else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wallah, we now have modified a bit to make analysis process easier. \n",
    "First, we will focus on fiding the best customers. This contains 2 parts: Find the ranking mechanism and the then dtermine the threshold to identify the best customers. \n",
    "\n",
    "### Finding the ranking mechanism\n",
    "\n",
    "Due to time constraints, you decided to use a very simple weighted sum model to classify customers. In this model, you decide to take 2 criteria into account: Amount spent and number of purchases made, and that the scores should be the same weight: (0.5* number of purchases + 0.5* amount spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_churn[\"nr_of_trans\"]=group_by_customer.size() # find the number of transactions by each customer\n",
    "best_churn[\"amount_spent\"] = group_by_customer.sum() # find the total amount spent by each customer\n",
    "best_churn.drop(\"trans_date\", axis = \"columns\", inplace = True) # drop the trans_date column, not necessary anymore for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the problem with ths model is that since the wweight for both criteria is the same (.5) and sometimes the amount spent is much higher than the total number of transactions, the score could be misleading. For instance, if the customer 1 spent 500 dollars with 2 purchases, the score would be 251, while if the customer 2 spent 400 dollars with 20 purchases, the score would be 210. It is obvious that the customer 2 is more a regular customer than customer 1 but has lower score on the ranking. To fix this problem, we would use a technique called min-max feature scalling. The goal of this technique is to compare different scales in a meaningful way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churned</th>\n",
       "      <th>nr_of_trans</th>\n",
       "      <th>amount_spent</th>\n",
       "      <th>scaled_trans</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>FM4424</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM4320</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2647</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.897270</td>\n",
       "      <td>93.434934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM3799</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2513</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>88.171182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM5109</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2506</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.846624</td>\n",
       "      <td>86.616892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM3805</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2453</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>85.665025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM5752</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2612</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.884698</td>\n",
       "      <td>85.663485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM4074</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.830819</td>\n",
       "      <td>84.398091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM4660</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2527</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>84.136905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM1215</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2362</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.794899</td>\n",
       "      <td>84.030686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FM2620</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2360</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.794181</td>\n",
       "      <td>83.994766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             churned  nr_of_trans  amount_spent  scaled_trans  scaled_amount  \\\n",
       "customer_id                                                                    \n",
       "FM4424             0           39          2933      1.000000       1.000000   \n",
       "FM4320             0           38          2647      0.971429       0.897270   \n",
       "FM3799             1           36          2513      0.914286       0.849138   \n",
       "FM5109             0           35          2506      0.885714       0.846624   \n",
       "FM3805             1           35          2453      0.885714       0.827586   \n",
       "FM5752             0           33          2612      0.828571       0.884698   \n",
       "FM4074             1           34          2462      0.857143       0.830819   \n",
       "FM4660             0           33          2527      0.828571       0.854167   \n",
       "FM1215             1           35          2362      0.885714       0.794899   \n",
       "FM2620             1           35          2360      0.885714       0.794181   \n",
       "\n",
       "                  score  \n",
       "customer_id              \n",
       "FM4424       100.000000  \n",
       "FM4320        93.434934  \n",
       "FM3799        88.171182  \n",
       "FM5109        86.616892  \n",
       "FM3805        85.665025  \n",
       "FM5752        85.663485  \n",
       "FM4074        84.398091  \n",
       "FM4660        84.136905  \n",
       "FM1215        84.030686  \n",
       "FM2620        83.994766  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_churn[\"scaled_trans\"] = (best_churn[\"nr_of_trans\"] - best_churn[\"nr_of_trans\"].min())\\\n",
    "/(best_churn[\"nr_of_trans\"].max()- best_churn[\"nr_of_trans\"].min()) # scale number of transactions\n",
    "best_churn[\"scaled_amount\"]=(best_churn[\"amount_spent\"]-best_churn[\"amount_spent\"].min())\\\n",
    "/(best_churn[\"amount_spent\"].max()-best_churn[\"amount_spent\"].min()) # scale total amount spent\n",
    "\n",
    "# find the score of each customer for ranking mechanism\n",
    "best_churn[\"score\"]=100*(.5*best_churn['scaled_trans']+.5*best_churn['scaled_amount'])\n",
    "\n",
    "# sorting score volumn in desceding order\n",
    "best_churn.sort_values(\"score\", inplace= True, ascending= False)\n",
    "best_churn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a way to compare customers, we need to decide on a threshold to determine which customers are \"the best\". We could use advanced techniques like k-means clustering, hierarchical clustering, or employ some machine learning algorithm, but would take a lot of time. \n",
    "\n",
    "### Determine the threshold \n",
    "\n",
    "Here are some factores that you decided to take into account:\n",
    "- The budget is $1000\n",
    "- No indication was given about how much coupon would be worth - it's up to you to decide\n",
    "- The coupons need to be good enough to prompt people to actually use them\n",
    "- They can't be too high because: (1) that reduces the number of customers who get them, (2) it would be like giving away money, (3) due to price dumping, it could be illegal\n",
    "- From your experience of shopping, a 30% discount coupon is already tempting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coupons: 19.4975736\n",
      "Number of people will receive coupon: 51.28843314123969\n"
     ]
    }
   ],
   "source": [
    "coupon = data['tran_amount'].mean() * .3 # see the value of coupon\n",
    "nr_of_people = 1000/coupon # see how many people would get the coupon\n",
    "print(\"Number of coupons:\", coupon)\n",
    "print(\"Number of people will receive coupon:\", nr_of_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 19.49xxxx is quite odd a value of a coupon, we would move it up 20 dollars/coupon. Then the number of people received it would be 50 people then. We can then choose 50 best customer from the best_churn dataframe above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_best_customers = best_churn.loc[best_churn['churned']==1].head(50) # choose the best customers\n",
    "\n",
    "top_50_best_customers.to_csv(\"best_customers.txt\") # save data to a different file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
